{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPafOI8WJbvOp0SZ6Yok/YL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GMgoes/machine-learning-colabority/blob/main/DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVDRqnoaKVbF",
        "outputId": "bfda2308-a649-49f0-f80e-cd09e194dbff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9492778660769815\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Base de dados OpenML = https://www.openml.org/search?type=data&status=any&id=180\n",
        "data, target = fetch_openml(data_id = 180, as_frame=True, return_X_y= True)\n",
        "\n",
        "# Os nossos dados estão desproporcionais em relação à quantidade, para isso, usamos o RandomOverSampler\n",
        "# para nivelarmos a quantidade que temos (Duplicando objetos que estão em menor quantidade)\n",
        "sampler = RandomOverSampler()\n",
        "data, target = sampler.fit_resample(data, target)\n",
        "\n",
        "# Obtendo as classes (Sete tipos de árvores que podem existir nas quatro regiões do parque nacional)\n",
        "classes = list(np.unique(target))\n",
        "\n",
        "# Fazendo o Train Test Split (TTS) dos que serão utilizados para treino e que serão utilizados para teste\n",
        "# Podemos fazer o TTS nesse caso, pois possuímos uma grande quantidade de dados, vamos fazer 70% para treino e 30% para teste\n",
        "x_train, x_test, y_train, y_test  = train_test_split(data, target, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Treinando os dados através de uma árvore de decisão\n",
        "clf = DecisionTreeClassifier(random_state = 0)\n",
        "# Treinamos com os dados disponibiizados para treino X e Y (Data e Target referente à 70% dos nossos dados)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# Mensuramos quanto nosso modelo consegue acertar com dados antes não vistos (Data referente à 30% dos nossos dados)\n",
        "predict = clf.predict(x_test)\n",
        "\n",
        "# Mensuramos a acurácia, ou seja, comparamos o que ele falou que era com o que realmente é (Target referente à 30% dos nossos dados)\n",
        "accuracy = accuracy_score(predict, y_test)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Plotando os dados e exibindo a matrix de confusão (TP, TN, FP, FN)\n",
        "#cm = confusion_matrix(y_test, predict, labels = classes)\n",
        "#disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = classes)\n",
        "#disp.plot()\n",
        "#plt.show()\n",
        "\n",
        "# Plotando os dados e exibindo no formato de Árvore\n",
        "#plot_tree(clf, max_depth = 5, filled = True)\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultado com Data = 50% e Target = 50% -> ~ 93% <br>\n",
        "Resultado com Data = 60% e Target = 40% -> ~ 92% <br>\n",
        "Resultado com Data = 70% e Target = 30% -> ~ 94% <br>\n",
        "Resultado com Data = 80% e Target = 20% -> ~ 94%"
      ],
      "metadata": {
        "id": "-rIxcnoHmwx2"
      }
    }
  ]
}